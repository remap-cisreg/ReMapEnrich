---
title: "ReMapEnrich: Statistical validation"
author: "Martin Mestdagh, Zacharie Ménétrier"
date: "`r Sys.Date()`"
package: "`r pkg_ver('ReMapEnrich')`"
vignette: >
    %\VignetteIndexEntry{ReMapEnrich-statistical-validation}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
output: 
    BiocStyle::html_document
bibliography: 
    bibliography.bib
csl:
    biomed-central.csl
---

```{r, echo=FALSE, message=FALSE}
knitr::opts_chunk$set(collapse = T, comment = "#>", eval=TRUE)
options(tibble.print_min = 4L, tibble.print_max = 4L)
library(dplyr)
```

# Abstract

In this vignette we will discuss about the statistical mechanics implied in this package, the results given by statistical validations and how to replicate those results with enough simplicity to statistically validate any experience.

# Poisson distribution

## Quick debrief

Let's repeat quickly what happens in an enrichment computation.

1. The query is overlapped against the catalogue and for each entry of the catalogue, the number of time a region of the query overlapped with it is counted and stored.

2. Shuffles regions are created from the query regions and the point 1 is repeated a certain number of time replacing the user's query with a new shuffle each time.

3. When all the shuffles are done, we now have for each category of the catalogue, the number of time it overlapped with the query regions and the mean number of time it overlapped with a shuffled regions.

## Overlaps number vs. random average

We now have to confront those two properties in a statistical method. From many others, the Poisson distribution has been chosen. First for his simplicity (only takes one parameter - the lambda which is in our case the random average) and secondly because it applies nicely to the genomic overlapping problem considering we don't take in account the width of each overlap but only its absence or presence in a genomic sequence on which oftenly applies time sequence related tools and method (Hidden Markov Model for example).

The upper or lower (depending on the given parameter 'tail') Poisson distribution p-value is now simply extracted from the number of overlaps and the random average for each category of the catalogue. Further corrections are applied as multiple p-values are calculated and stored in the q-value column of the enrichment data frame.

# Verifying the statistical distribution

So long, we assumed that overlapping number in a shuffled/random query against a catalogue followed the Poisson distribution. We now have to verify that assumption on previous experimetns and on a random catalogue.

## Poisson distribution on the ReMap catalogue

The function RandomIntersections is designed to help verifying statistical distribution. All it does is replicating overlaps computations on random regions vs. a given catalogue and returning all the results for each category at every iteration.

```{r, echo=FALSE, eval = FALSE}
# Quick demonstration
library(ReMapEnrich)
demo.dir <- "~/ReMapEnrich_demo"
dir.create(demo.dir, showWarnings = FALSE, recursive = TRUE)
setwd(demo.dir)
catalog <- bedToGranges(downloadRemapCatalog("ReMapEnrich_demo"))
randomRegionsVsReMap <- randomIntersections(catalog, iterations = 500, regionNb = 1000, regionSize = 1000)
```

As for a solid statistical validation we need to make at least 10,000 iterations and as this will take 30 minutes on a decent computer, results of 10,000 random intersections has been stored in this package and can be easily retrieved.

```{r}
data("random_regions_vs_ReMap", package = "ReMapEnrich")
head(randomRegionsVsReMap, n = 1)
```

We now obtained results of overlapping for 10,000 random regions against the ReMap catalogue. We want to check if such results follow the Poisson distribution. A function has been implemented in the package to get a goodness of fit test of the random intersections vs. the Poisson distribution.


```{r}
chi2results <- fitPoisson(randomRegionsVsReMap, showCategories = FALSE)
head(chi2results)
```

The goodness of fit test is obtained with a chi2 comparison for each class of the histogram of the random distribution vs. the Poisson distribution with the corresponding lambda (which is obtained from the mean of the random intersections for each category of the catalogue). This kind of results can be obfuscating for amateur statisticians. That's why we will now present some results in a graphical representation for some of the category (237 in total).

```{r}
# An easy to do function to create histogram for any result for a category
MakeHistogram <- function(results) {
    h <- hist(results, breaks = -1:(max(results)+1), plot = FALSE)
    expOverlaps <- dpois(x = 0:(max(results)+1), lambda = mean(results)) * sum(h$counts)
    plot(h$counts, col ="red", type = 'h', xaxt = 'nt',
         xlab = "Number of overlaps", ylab = "Number of occurences",
         main = paste("Empirical distribution vs. Poisson distribution for", deparse(substitute(results)))
    )
    axis(side = 1 ,labels = c(0:max(results)), at = c(1:(max(results)+1)))
    lines(expOverlaps, col = "blue")
    legend("topright",
           paste(
            "mean = ", mean(results),
            "\nvariance = ", var(results)
        ), cex = 0.6, bty = 'n'
    )
}
# The best fit is RUNX2
RUNX2 <- randomRegionsVsReMap[,"RUNX2"]
MakeHistogram(RUNX2)
# SOX2 is an average fit
SOX2 <- randomRegionsVsReMap[,"SOX2"]
MakeHistogram(SOX2)
# The worst fit is BRF1
BRF1 <- randomRegionsVsReMap[,"BRF1"]
MakeHistogram(BRF1)
```

## Poisson distribution on random catalogue

After verifying the fit on Poisson distribution for the ReMap catalogue we now want to check on a totally random catalogue to see if the Poisson distribution is still the best to follow.

```{r, echo=TRUE}
# Creating a random catalogue with only one category 'Vert'.
randomCatalog <- genRegions(10000, 200)
# Reduce is a GenomicRanges function designed to merge overlapping regions.
randomCatalog <- reduce(randomCatalog)
# Creating one category for each regions.
randomCatalog@elementMetadata$id = "Vert"
randomCatalogIntersections <- randomIntersections(randomCatalog, iterations = 500, regionNb = 1000, regionSize = 1000)
MakeHistogram(randomCatalogIntersections)
```

On this example, only 500 iterations have been made and we can already see that the Poisson distribution seems to nicely describe our empirical values.

# Statistically validate your experiments

After any enrichment experiments, you may want to ensure that the statistical methods involved, are still valid.
Let's make an enrichment analysis with further statistical validations. If you don't understand all the parameters in this experiment, please refer to the "Advanced use" vignette before.

```{r, eval = FALSE}
catalog <- bedToGranges(downloadRemapCatalog("demo.dir"))
query <- bedToGranges(downloadEncodePeaks("ENCFF001VCU", "demo.dir"))
universe <- bedToGranges(downloadEncodePeaks("ENCFF718QVA", "demo.dir"))
enrichment <- enrichment(query, catalog, universe = universe, byChrom = TRUE, shuffles = 10, included = 0.5, nCores = 7)
```

To validate such an enrichment we need to apply the function RandomIntersections with the exact same parameters. Most important, we will now obtain our random regions through the parameter 'shuffle' as we want to ensure that the same conditions apply in the experiment which use shuffled regions and not randomly generated regions.

```{r, eval = FALSE}
randomIntersections <- randomIntersections(catalog, iterations = 10000, universe = universe, included = 0.5, shuffle = query, byChrom = TRUE)
chi2results <- fitPoisson(randomIntersections)
```

This part of the vignette is not evaluated as 10,000 iterations may take a long time even when parallelizing to maximum (refer to parameter 'nCores' for more details). It is only here as an example to reproduce validation with any enrichment computation you want to validate more consequently.
